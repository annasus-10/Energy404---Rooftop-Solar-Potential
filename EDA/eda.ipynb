{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3528848",
   "metadata": {},
   "source": [
    "### Step 1 — Load + schema + basic health checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d310548d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.9' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/User/AppData/Local/Microsoft/WindowsApps/python3.13.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "COMBINED = Path(\"C:/Users/User/Desktop/ML/Project/solar-potential-analysis-github-setup/cleaned_datasets/all_cities_clean.parquet\")\n",
    "df = pd.read_parquet(COMBINED)\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nDtypes:\\n\", df.dtypes)\n",
    "\n",
    "# quick null audit\n",
    "nulls = df.isna().sum().sort_values(ascending=False)\n",
    "print(\"\\nNull counts:\\n\", nulls[nulls>0])\n",
    "\n",
    "# unique values for keys\n",
    "print(\"\\nCities (n):\", df[\"City\"].nunique())\n",
    "print(\"Building types (n):\", df[\"Assumed_building_type\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab363c55",
   "metadata": {},
   "source": [
    "### Step 2 — Coverage by city and by building type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c9688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows per city\n",
    "city_counts = df[\"City\"].value_counts().rename_axis(\"City\").reset_index(name=\"rows\")\n",
    "display(city_counts.head(30)); print(\"TOTAL rows:\", city_counts[\"rows\"].sum())\n",
    "\n",
    "# rows per building type \n",
    "bt_counts = df[\"Assumed_building_type\"].value_counts(dropna=False).sort_index()\n",
    "display(bt_counts.rename(\"rows\").to_frame())\n",
    "\n",
    "# heatmap-like pivot (counts): City × Building Type\n",
    "pivot_counts = pd.pivot_table(df, index=\"City\", columns=\"Assumed_building_type\", values=\"Surface_area\", aggfunc=\"count\", fill_value=0)\n",
    "pivot_counts.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ee3d5a",
   "metadata": {},
   "source": [
    "### Step 3 — Domain sanity checks (no engineered features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e9a9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "checks = {}\n",
    "\n",
    "# 3.1 Potential_installable_area should be ≤ Surface_area (allow NaNs)\n",
    "bad_area = df[(df[\"Potential_installable_area\"].notna()) &\n",
    "              (df[\"Surface_area\"].notna()) &\n",
    "              (df[\"Potential_installable_area\"] > df[\"Surface_area\"])]\n",
    "\n",
    "checks[\"area_ratio_violations\"] = len(bad_area)\n",
    "\n",
    "# 3.2 Non-negativity\n",
    "nonneg_cols = [\"Surface_area\", \"Potential_installable_area\", \"Peak_installable_capacity\", \"Energy_potential_per_year\", \"Estimated_tilt\"]\n",
    "for col in nonneg_cols:\n",
    "    checks[f\"negatives_in_{col}\"] = int((df[col] < 0).sum(skipna=True))\n",
    "\n",
    "# 3.3 Tilt within [0, 90]\n",
    "tilt_out = df[\"Estimated_tilt\"].dropna()\n",
    "checks[\"tilt_out_of_range\"] = int(((tilt_out < 0) | (tilt_out > 90)).sum())\n",
    "\n",
    "# Report\n",
    "checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69372e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(bad_area.index)\n",
    "print(\"Dropped\", len(bad_area), \"rows with invalid area ratios.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a376cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd118a5",
   "metadata": {},
   "source": [
    "### Step 4 — Univariate distributions (existing columns only, sampled for speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b569eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "NUMERIC = [\"Surface_area\",\"Potential_installable_area\",\"Peak_installable_capacity\",\"Energy_potential_per_year\",\"Estimated_tilt\"]\n",
    "\n",
    "# stratified-ish sample by city (cap ~200k total)\n",
    "per_city = 8000\n",
    "parts = []\n",
    "for c, g in df.groupby(\"City\", sort=False):\n",
    "    parts.append(g.sample(min(len(g), per_city), random_state=42))\n",
    "df_s = pd.concat(parts, ignore_index=True)\n",
    "\n",
    "print(\"Sampled shape:\", df_s.shape)\n",
    "\n",
    "for col in NUMERIC:\n",
    "    s = df_s[col].dropna()\n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.hist(s, bins=60)\n",
    "    plt.title(col)\n",
    "    plt.xlabel(col); plt.ylabel(\"count\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c21055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "NUMERIC = [\"Surface_area\",\"Potential_installable_area\",\"Peak_installable_capacity\",\n",
    "           \"Energy_potential_per_year\",\"Estimated_tilt\"]\n",
    "\n",
    "# 1) Zero share + robust quantiles\n",
    "summary = []\n",
    "for col in NUMERIC:\n",
    "    s = df_s[col].dropna()\n",
    "    zeros = int((s==0).sum())\n",
    "    q = s.quantile([0.5, 0.9, 0.95, 0.99, 0.999])\n",
    "    summary.append({\n",
    "        \"col\": col,\n",
    "        \"n\": int(s.size),\n",
    "        \"zeros\": zeros,\n",
    "        \"zero_share\": round(zeros/max(1,s.size), 4),\n",
    "        \"p50\": q.loc[0.5],\n",
    "        \"p90\": q.loc[0.9],\n",
    "        \"p95\": q.loc[0.95],\n",
    "        \"p99\": q.loc[0.99],\n",
    "        \"p999\": q.loc[0.999],\n",
    "        \"max\": s.max()\n",
    "    })\n",
    "pd.DataFrame(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f22ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Re-plot (A) clipped at 99th percentile and (B) log-scale\n",
    "for col in NUMERIC:\n",
    "    s = df_s[col].dropna()\n",
    "\n",
    "    # (A) Clip view at 99th percentile so the bulk is visible\n",
    "    p99 = s.quantile(0.99)\n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.hist(s[s<=p99], bins=60)\n",
    "    plt.title(f\"{col} (≤ p99)\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "    # (B) Log-view to reveal the body + tail together (skip nonpositive)\n",
    "    s_pos = s[s>0]\n",
    "    if len(s_pos) > 0:\n",
    "        plt.figure(figsize=(6,3))\n",
    "        plt.hist(np.log10(s_pos), bins=60)\n",
    "        plt.title(f\"{col} (log10 scale, >0 only)\")\n",
    "        plt.xlabel(f\"log10({col})\"); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077168ab",
   "metadata": {},
   "source": [
    "### Step 5 — relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4872cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# A) Potential_installable_area vs Surface_area\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.hexbin(df_s[\"Surface_area\"], df_s[\"Potential_installable_area\"], gridsize=60, mincnt=1)\n",
    "plt.xlabel(\"Surface_area\"); plt.ylabel(\"Potential_installable_area\"); plt.title(\"Potential vs Surface\")\n",
    "plt.colorbar(label=\"count\"); plt.tight_layout(); plt.show()\n",
    "\n",
    "# B) Peak_installable_capacity vs Potential_installable_area\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.hexbin(df_s[\"Potential_installable_area\"], df_s[\"Peak_installable_capacity\"], gridsize=60, mincnt=1)\n",
    "plt.xlabel(\"Potential_installable_area\"); plt.ylabel(\"Peak_installable_capacity\"); plt.title(\"Peak capacity vs Potential area\")\n",
    "plt.colorbar(label=\"count\"); plt.tight_layout(); plt.show()\n",
    "\n",
    "# C) Energy_potential_per_year vs Peak_installable_capacity\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.hexbin(df_s[\"Peak_installable_capacity\"], df_s[\"Energy_potential_per_year\"], gridsize=60, mincnt=1)\n",
    "plt.xlabel(\"Peak_installable_capacity\"); plt.ylabel(\"Energy_potential_per_year\"); plt.title(\"Energy vs Peak capacity\")\n",
    "plt.colorbar(label=\"count\"); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88e7e90",
   "metadata": {},
   "source": [
    "Potential vs Surface: tight, near-linear band from the origin → potential area scales with roof size (good). A few huge roofs pull the axes—likely legit large sites.\n",
    "\n",
    "Peak capacity vs Potential area: again ~linear → implies an almost constant W/m² across records (expected for PV density).\n",
    "\n",
    "Energy per year vs Peak capacity: roughly linear with some spread → different climates/tilts/shading → capacity-factor differences. Still coherent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad851bb",
   "metadata": {},
   "source": [
    "### Step 6 — group comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde063d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# (recompute if you restarted)\n",
    "city_counts = df[\"City\"].value_counts().rename_axis(\"City\").reset_index(name=\"rows\")\n",
    "\n",
    "# Boxplots by city (Energy_potential_per_year)\n",
    "cities = city_counts.head(30)[\"City\"].tolist()\n",
    "subset = df[df[\"City\"].isin(cities)][[\"City\",\"Energy_potential_per_year\"]].dropna()\n",
    "\n",
    "plt.figure(figsize=(50,6))\n",
    "subset.boxplot(by=\"City\", column=\"Energy_potential_per_year\", rot=90)\n",
    "plt.suptitle(\"\")\n",
    "plt.title(\"Energy_potential_per_year by City\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Boxplots by building type (Peak_installable_capacity)\n",
    "plt.figure(figsize=(6,3))\n",
    "df[[\"Assumed_building_type\",\"Peak_installable_capacity\"]].dropna().boxplot(\n",
    "    by=\"Assumed_building_type\", column=\"Peak_installable_capacity\"\n",
    ")\n",
    "plt.suptitle(\"\")\n",
    "plt.title(\"Peak_installable_capacity by Building Type\")\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cde58c",
   "metadata": {},
   "source": [
    "### Step 7 — Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b596bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def to_builtin(o):\n",
    "    if isinstance(o, np.generic):\n",
    "        return o.item()\n",
    "    if isinstance(o, dict):\n",
    "        return {to_builtin(k): to_builtin(v) for k, v in o.items()}\n",
    "    if isinstance(o, (list, tuple, set)):\n",
    "        return [to_builtin(x) for x in o]\n",
    "    return o\n",
    "\n",
    "# if you still have report from above:\n",
    "out_path = Path(\"data_quality_report.json\")\n",
    "clean_report = to_builtin(report)\n",
    "out_path.write_text(json.dumps(clean_report, indent=2))\n",
    "print(f\"wrote {out_path.as_posix()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccb21b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "NUMERIC = [\"Surface_area\",\"Potential_installable_area\",\"Peak_installable_capacity\",\n",
    "           \"Energy_potential_per_year\",\"Estimated_tilt\"]\n",
    "\n",
    "# for huge data we use df_s made in Step 4; fall back to df if needed\n",
    "X = df_s if \"df_s\" in globals() else df\n",
    "X = X[NUMERIC + [\"City\",\"Assumed_building_type\"]].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c4c83d",
   "metadata": {},
   "source": [
    "**Robust univariate outliers (IQR + MAD)**\n",
    "\n",
    "IQR rule: values outside [Q1−k·IQR, Q3+k·IQR], default k=1.5 (use 3.0 to be gentler).\n",
    "\n",
    "MAD-z rule: |x−median| / (1.4826*MAD) > c, default c=3.5 (very robust).\n",
    "\n",
    "For strictly-positive columns we also check log10 space to handle heavy right tails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46bfb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr_mask(s, k=1.5):\n",
    "    q1, q3 = s.quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    lo, hi = q1 - k*iqr, q3 + k*iqr\n",
    "    return (s < lo) | (s > hi)\n",
    "\n",
    "def mad_mask(s, c=3.5):\n",
    "    med = s.median()\n",
    "    mad = (s - med).abs().median()\n",
    "    if mad == 0 or np.isnan(mad):\n",
    "        return pd.Series(False, index=s.index)\n",
    "    z = (s - med).abs() / (1.4826 * mad)\n",
    "    return z > c\n",
    "\n",
    "def positive_log_mask(s, rule=\"iqr\", k=1.5, c=3.5):\n",
    "    # only consider strictly positive values for log check\n",
    "    mpos = s > 0\n",
    "    s_pos = np.log10(s[mpos])\n",
    "    if rule == \"iqr\":\n",
    "        mask = iqr_mask(s_pos, k=k)\n",
    "    else:\n",
    "        mask = mad_mask(s_pos, c=c)\n",
    "    out = pd.Series(False, index=s.index)\n",
    "    out.loc[mpos] = mask.values\n",
    "    return out\n",
    "\n",
    "positive_cols = [\"Surface_area\",\"Potential_installable_area\",\"Peak_installable_capacity\",\"Energy_potential_per_year\"]\n",
    "tilt_col = \"Estimated_tilt\"\n",
    "\n",
    "uni_out = {}\n",
    "\n",
    "for col in NUMERIC:\n",
    "    s = X[col].dropna()\n",
    "    m_iqr = iqr_mask(s, k=1.5)\n",
    "    m_mad = mad_mask(s, c=3.5)\n",
    "\n",
    "    # add log check for positive cols\n",
    "    if col in positive_cols:\n",
    "        m_log = positive_log_mask(s, rule=\"iqr\", k=1.5)\n",
    "        m_log_mad = positive_log_mask(s, rule=\"mad\", c=3.5)\n",
    "    else:\n",
    "        m_log = pd.Series(False, index=s.index)\n",
    "        m_log_mad = pd.Series(False, index=s.index)\n",
    "\n",
    "    uni_out[col] = {\n",
    "        \"n\": int(s.size),\n",
    "        \"iqr_outliers\": int(m_iqr.sum()),\n",
    "        \"mad_outliers\": int(m_mad.sum()),\n",
    "        \"log_iqr_outliers\": int(m_log.sum()),\n",
    "        \"log_mad_outliers\": int(m_log_mad.sum()),\n",
    "        \"p99\": float(s.quantile(0.99)),\n",
    "        \"p999\": float(s.quantile(0.999)),\n",
    "        \"max\": float(s.max())\n",
    "    }\n",
    "\n",
    "pd.DataFrame(uni_out).T.sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ab7e22",
   "metadata": {},
   "source": [
    "**Group-wise outliers (by City and by Building Type)**\n",
    "\n",
    "This checks whether some values are outliers within their city/type (fairer when cities differ in scale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ae01d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_outlier_counts(frame, group_col, val_col, rule=\"iqr\", k=1.5, c=3.5, log_for_positive=True):\n",
    "    rows = []\n",
    "    pos = val_col in positive_cols\n",
    "    for g, sub in frame[[group_col, val_col]].dropna().groupby(group_col, sort=False):\n",
    "        s = sub[val_col]\n",
    "        masks = []\n",
    "\n",
    "        if rule == \"iqr\":\n",
    "            masks.append(iqr_mask(s, k=k))\n",
    "            if log_for_positive and pos:\n",
    "                masks.append(positive_log_mask(s, rule=\"iqr\", k=k))\n",
    "        else:\n",
    "            masks.append(mad_mask(s, c=c))\n",
    "            if log_for_positive and pos:\n",
    "                masks.append(positive_log_mask(s, rule=\"mad\", c=c))\n",
    "\n",
    "        m = masks[0]\n",
    "        for mm in masks[1:]:\n",
    "            m = m | mm\n",
    "\n",
    "        rows.append({\"group\": g, \"n\": int(s.size), \"outliers\": int(m.sum()),\n",
    "                     \"share\": float(m.mean())})\n",
    "    out = pd.DataFrame(rows).sort_values(\"share\", ascending=False)\n",
    "    return out\n",
    "\n",
    "# Example: by City for Energy, and by Building type for Peak capacity\n",
    "city_energy = group_outlier_counts(X, \"City\", \"Energy_potential_per_year\", rule=\"iqr\", k=1.5)\n",
    "bt_peak     = group_outlier_counts(X, \"Assumed_building_type\", \"Peak_installable_capacity\", rule=\"iqr\", k=1.5)\n",
    "\n",
    "city_energy.head(15), bt_peak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e8c68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_extremes(df_full, column, n=12):\n",
    "    s = df_full[column].dropna()\n",
    "    top_idx = s.nlargest(n).index\n",
    "    cols = [\"City\",\"Assumed_building_type\", column]\n",
    "    display(df_full.loc[top_idx, cols])\n",
    "\n",
    "for col in NUMERIC:\n",
    "    print(f\"\\nTop extremes for {col}:\")\n",
    "    show_top_extremes(df, col, n=12)  # use full df here to see true top rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4817f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# City vs Energy on log-y\n",
    "sub = df[df[\"City\"].isin(df[\"City\"].value_counts().head(10).index)]\n",
    "plt.figure(figsize=(10,4))\n",
    "sub.boxplot(by=\"City\", column=\"Energy_potential_per_year\", rot=45)\n",
    "plt.yscale(\"log\"); plt.suptitle(\"\"); plt.title(\"Energy per year by City (log-y)\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Building type vs Peak capacity on log-y\n",
    "plt.figure(figsize=(7,3))\n",
    "df[[\"Assumed_building_type\",\"Peak_installable_capacity\"]].dropna().boxplot(\n",
    "    by=\"Assumed_building_type\", column=\"Peak_installable_capacity\")\n",
    "plt.yscale(\"log\"); plt.suptitle(\"\"); plt.title(\"Peak capacity by Building Type (log-y)\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd9d99a",
   "metadata": {},
   "source": [
    "### Step 7b — correlation heatmaps for the specified columns (no City)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59555aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Correlation heatmaps (EXISTING columns only) ===\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "OUT_DIR = Path(\"cleaned_datasets\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Columns you specified (no City)\n",
    "cols = [\n",
    "    \"Surface_area\",\n",
    "    \"Potential_installable_area\",\n",
    "    \"Peak_installable_capacity\",\n",
    "    \"Energy_potential_per_year\",\n",
    "    \"Assumed_building_type\",  # already label-encoded\n",
    "    \"Estimated_tilt\",\n",
    "]\n",
    "cols = [c for c in cols if c in df.columns]\n",
    "\n",
    "# Use sampled df_s if it exists; otherwise lightly sample for speed\n",
    "if \"df_s\" in globals():\n",
    "    base = df_s\n",
    "else:\n",
    "    base = df.sample(n=min(len(df), 200_000), random_state=42)\n",
    "\n",
    "X = base[cols].copy()\n",
    "if \"Assumed_building_type\" in X:  # ensure numeric dtype\n",
    "    X[\"Assumed_building_type\"] = pd.to_numeric(X[\"Assumed_building_type\"], errors=\"coerce\")\n",
    "\n",
    "# Correlations\n",
    "corr_pearson  = X.corr(method=\"pearson\")\n",
    "corr_spearman = X.corr(method=\"spearman\")\n",
    "\n",
    "def plot_heatmap(corr, title, out_path):\n",
    "    c = corr.copy()\n",
    "    arr = c.values.astype(float)\n",
    "    mask = np.triu(np.ones_like(arr, dtype=bool))         # show lower triangle\n",
    "    arr_masked = np.ma.masked_where(mask, arr)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(1.0 + 0.7*len(c.columns), 1.0 + 0.7*len(c.columns)))\n",
    "    im = ax.imshow(arr_masked, aspect='auto')\n",
    "\n",
    "    ax.set_xticks(range(len(c.columns))); ax.set_xticklabels(c.columns, rotation=45, ha=\"right\")\n",
    "    ax.set_yticks(range(len(c.columns))); ax.set_yticklabels(c.columns)\n",
    "\n",
    "    # annotate lower triangle\n",
    "    for i in range(len(c.columns)):\n",
    "        for j in range(len(c.columns)):\n",
    "            if j <= i and not np.isnan(c.iat[i,j]):\n",
    "                ax.text(j, i, f\"{c.iat[i,j]:.2f}\", ha=\"center\", va=\"center\", fontsize=9)\n",
    "\n",
    "    cb = fig.colorbar(im, ax=ax, shrink=0.85); cb.ax.set_ylabel(\"Correlation\", rotation=90, va=\"center\")\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(out_path, dpi=220, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "plot_heatmap(corr_pearson,  \"Correlation (Pearson) — Existing Columns\",  OUT_DIR / \"_corr_SPECIFIED_pearson.png\")\n",
    "plot_heatmap(corr_spearman, \"Correlation (Spearman) — Existing Columns\", OUT_DIR / \"_corr_SPECIFIED_spearman.png\")\n",
    "\n",
    "print(\"Saved:\",\n",
    "      (OUT_DIR / \"_corr_SPECIFIED_pearson.png\").as_posix(),\n",
    "      (OUT_DIR / \"_corr_SPECIFIED_spearman.png\").as_posix())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
