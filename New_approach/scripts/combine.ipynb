{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13ad7182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "COMBINED = Path(\"C:/Users/User/Desktop/ML/Project/solar-potential-analysis-github-setup/New_approach/dataset/reference/all_cities_clean.parquet\")   # your big combined file\n",
    "WEATHER  = Path(\"C:/Users/User/Desktop/ML/Project/solar-potential-analysis-github-setup/New_approach/weather_api_integration/city_weather.csv\")               # the NASA file we made\n",
    "OUT_DIR  = Path(\"C:/Users/User/Desktop/ML/Project/solar-potential-analysis-github-setup/New_approach/dataset/cleaned_datasets\"); OUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "547f6260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (6530761, 7) (25, 5)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(COMBINED)\n",
    "weather = pd.read_csv(WEATHER)\n",
    "print(\"Loaded:\", df.shape, weather.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bb1c706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After merge: (6530761, 13)\n",
      "avg_GHI_kWhm2_day    0\n",
      "avg_temp_C           0\n",
      "clearness_index      0\n",
      "precip_mm_day        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# map dataset city names → weather city names\n",
    "city_fix_map = {\n",
    "    \"DarEsSalaam\": \"Dar es Salaam\",\n",
    "    \"GreatDhakaRegion\": \"Dhaka\",\n",
    "    \"Honduras\": \"San Pedro Sula\",\n",
    "    \"Lagos\": \"Lagos State\",\n",
    "    \"LagosState\": \"Lagos State\",\n",
    "    \"Panama\": \"Panama City\",\n",
    "    \"SVG\": \"Saint Vincent and the Grenadines\",\n",
    "    \"StLucia\": \"Saint Lucia\",\n",
    "    \"StMaarten\": \"Sint Maarten\",\n",
    "    \"SouthAfrica\": \"Johannesburg\"\n",
    "}\n",
    "df[\"City_clean\"] = df[\"City\"].replace(city_fix_map)\n",
    "weather[\"City_clean\"] = weather[\"City\"].str.strip()\n",
    "\n",
    "dfm = df.merge(weather, on=\"City_clean\", how=\"left\", suffixes=(\"\", \"_w\"))\n",
    "print(\"After merge:\", dfm.shape)\n",
    "\n",
    "# quick check (should be all zeros)\n",
    "print(dfm[[\"avg_GHI_kWhm2_day\",\"avg_temp_C\",\"clearness_index\",\"precip_mm_day\"]].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17595520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename to clean names\n",
    "dfm = dfm.rename(columns={\n",
    "    \"Surface_area\": \"RoofSurface_m2\",\n",
    "    \"Potential_installable_area\": \"InstallableArea_m2\",\n",
    "    \"Peak_installable_capacity\": \"PeakCapacity_kWp\",\n",
    "    \"Energy_potential_per_year\": \"EnergyPotential_kWh\",\n",
    "    \"Assumed_building_type\": \"BuildingTypeEncoded\",\n",
    "    \"Estimated_tilt\": \"Tilt_deg\",\n",
    "    \"avg_GHI_kWhm2_day\": \"GHI_kWh_per_m2_day\",\n",
    "    \"avg_temp_C\": \"AvgTemp_C\",\n",
    "    \"clearness_index\": \"ClearnessIndex\",\n",
    "    \"precip_mm_day\": \"Precip_mm_per_day\",\n",
    "})\n",
    "\n",
    "# decode building type labels\n",
    "building_mapping = {\n",
    "    0: \"single family residential\",\n",
    "    1: \"multifamily residential\",\n",
    "    2: \"commercial\",\n",
    "    3: \"small commercial\",\n",
    "    4: \"industrial\",\n",
    "    5: \"public sector\",\n",
    "    6: \"peri-urban settlement\",\n",
    "    7: \"schools\",\n",
    "    8: \"public health facilities\",\n",
    "    9: \"hotels\"\n",
    "}\n",
    "dfm[\"BuildingType\"] = dfm[\"BuildingTypeEncoded\"].map(building_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ee955f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final ready-for-training shape/cols: (6243501, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>BuildingType</th>\n",
       "      <th>tilt</th>\n",
       "      <th>tilt2</th>\n",
       "      <th>tilt_sin</th>\n",
       "      <th>tilt_cos</th>\n",
       "      <th>GHI_kWh_per_m2_day</th>\n",
       "      <th>AvgTemp_C</th>\n",
       "      <th>ClearnessIndex</th>\n",
       "      <th>Precip_mm_per_day</th>\n",
       "      <th>kWh_per_m2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accra</td>\n",
       "      <td>multifamily residential</td>\n",
       "      <td>9.120000</td>\n",
       "      <td>83.174398</td>\n",
       "      <td>0.158503</td>\n",
       "      <td>0.987359</td>\n",
       "      <td>4.824408</td>\n",
       "      <td>27.070833</td>\n",
       "      <td>0.486667</td>\n",
       "      <td>3.935833</td>\n",
       "      <td>268.290184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accra</td>\n",
       "      <td>multifamily residential</td>\n",
       "      <td>21.690001</td>\n",
       "      <td>470.456123</td>\n",
       "      <td>0.369585</td>\n",
       "      <td>0.929197</td>\n",
       "      <td>4.824408</td>\n",
       "      <td>27.070833</td>\n",
       "      <td>0.486667</td>\n",
       "      <td>3.935833</td>\n",
       "      <td>254.086636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accra</td>\n",
       "      <td>multifamily residential</td>\n",
       "      <td>3.530000</td>\n",
       "      <td>12.460900</td>\n",
       "      <td>0.061571</td>\n",
       "      <td>0.998103</td>\n",
       "      <td>4.824408</td>\n",
       "      <td>27.070833</td>\n",
       "      <td>0.486667</td>\n",
       "      <td>3.935833</td>\n",
       "      <td>274.120557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accra</td>\n",
       "      <td>multifamily residential</td>\n",
       "      <td>18.360001</td>\n",
       "      <td>337.089622</td>\n",
       "      <td>0.314987</td>\n",
       "      <td>0.949096</td>\n",
       "      <td>4.824408</td>\n",
       "      <td>27.070833</td>\n",
       "      <td>0.486667</td>\n",
       "      <td>3.935833</td>\n",
       "      <td>273.618893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Accra</td>\n",
       "      <td>multifamily residential</td>\n",
       "      <td>10.680000</td>\n",
       "      <td>114.062407</td>\n",
       "      <td>0.185324</td>\n",
       "      <td>0.982678</td>\n",
       "      <td>4.824408</td>\n",
       "      <td>27.070833</td>\n",
       "      <td>0.486667</td>\n",
       "      <td>3.935833</td>\n",
       "      <td>264.811711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    City             BuildingType       tilt       tilt2  tilt_sin  tilt_cos  \\\n",
       "0  Accra  multifamily residential   9.120000   83.174398  0.158503  0.987359   \n",
       "2  Accra  multifamily residential  21.690001  470.456123  0.369585  0.929197   \n",
       "3  Accra  multifamily residential   3.530000   12.460900  0.061571  0.998103   \n",
       "4  Accra  multifamily residential  18.360001  337.089622  0.314987  0.949096   \n",
       "5  Accra  multifamily residential  10.680000  114.062407  0.185324  0.982678   \n",
       "\n",
       "   GHI_kWh_per_m2_day  AvgTemp_C  ClearnessIndex  Precip_mm_per_day  \\\n",
       "0            4.824408  27.070833        0.486667           3.935833   \n",
       "2            4.824408  27.070833        0.486667           3.935833   \n",
       "3            4.824408  27.070833        0.486667           3.935833   \n",
       "4            4.824408  27.070833        0.486667           3.935833   \n",
       "5            4.824408  27.070833        0.486667           3.935833   \n",
       "\n",
       "   kWh_per_m2  \n",
       "0  268.290184  \n",
       "2  254.086636  \n",
       "3  274.120557  \n",
       "4  273.618893  \n",
       "5  264.811711  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only rows with valid area (needed for the normalized target)\n",
    "eps = 1e-9\n",
    "mask = dfm[\"InstallableArea_m2\"].notna() & (dfm[\"InstallableArea_m2\"] > 0)\n",
    "dfm = dfm.loc[mask].copy()\n",
    "\n",
    "# new target\n",
    "dfm[\"kWh_per_m2\"] = dfm[\"EnergyPotential_kWh\"] / (dfm[\"InstallableArea_m2\"] + eps)\n",
    "\n",
    "# tilt variants\n",
    "dfm[\"tilt\"]      = dfm[\"Tilt_deg\"]\n",
    "dfm[\"tilt2\"]     = dfm[\"Tilt_deg\"]**2\n",
    "rad              = np.deg2rad(dfm[\"Tilt_deg\"].astype(float))\n",
    "dfm[\"tilt_sin\"]  = np.sin(rad)\n",
    "dfm[\"tilt_cos\"]  = np.cos(rad)\n",
    "\n",
    "# drop columns we don't want in the training file (leakage/helpers/encoded)\n",
    "drop_cols = [\n",
    "    \"City_clean\", \"City_w\",                # merge helpers\n",
    "    \"BuildingTypeEncoded\",                 # we’ll encode from the string later\n",
    "    \"EnergyPotential_kWh\", \"InstallableArea_m2\", \"RoofSurface_m2\", \"PeakCapacity_kWp\"  # leakage risks\n",
    "]\n",
    "df_final = dfm.drop(columns=[c for c in drop_cols if c in dfm.columns])\n",
    "\n",
    "# reorder to: id, labels, features, target\n",
    "cols_order = [\n",
    "    \"City\", \"BuildingType\",\n",
    "    \"tilt\",\"tilt2\",\"tilt_sin\",\"tilt_cos\",\n",
    "    \"GHI_kWh_per_m2_day\",\"AvgTemp_C\",\"ClearnessIndex\",\"Precip_mm_per_day\",\n",
    "    \"kWh_per_m2\"\n",
    "]\n",
    "df_final = df_final[cols_order]\n",
    "\n",
    "print(\"Final ready-for-training shape/cols:\", df_final.shape)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ba494b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_path = OUT_DIR / \"all_cities_weather_ready_train.csv\"\n",
    "# parq_path = OUT_DIR / \"all_cities_weather_ready_train.parquet\"\n",
    "\n",
    "# df_final.to_csv(csv_path, index=False)\n",
    "# df_final.to_parquet(parq_path, index=False)\n",
    "\n",
    "# print(\"Saved:\\n -\", csv_path.as_posix(), \"\\n -\", parq_path.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99ee3f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6243501 entries, 0 to 6530760\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   City                string \n",
      " 1   BuildingType        object \n",
      " 2   tilt                float64\n",
      " 3   tilt2               float64\n",
      " 4   tilt_sin            float64\n",
      " 5   tilt_cos            float64\n",
      " 6   GHI_kWh_per_m2_day  float64\n",
      " 7   AvgTemp_C           float64\n",
      " 8   ClearnessIndex      float64\n",
      " 9   Precip_mm_per_day   float64\n",
      " 10  kWh_per_m2          float64\n",
      "dtypes: float64(9), object(1), string(1)\n",
      "memory usage: 571.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4425ae9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top 10 cities by row count ===\n",
      "            City  row_count\n",
      "      LagosState    1327213\n",
      "GreatDhakaRegion     623809\n",
      "     DarEsSalaam     515669\n",
      "     Mexico City     506631\n",
      "     SouthAfrica     411885\n",
      "          Manila     295984\n",
      "         Nairobi     269249\n",
      "         Colombo     265446\n",
      "           Accra     265113\n",
      "         Karachi     263704\n",
      "\n",
      "=== Overall top 10 building types ===\n",
      "             BuildingType  row_count\n",
      "single family residential    4023492\n",
      "  multifamily residential    1420742\n",
      "               commercial     354091\n",
      "               industrial     150169\n",
      "            public sector     146366\n",
      "    peri-urban settlement      73521\n",
      "                  schools      35395\n",
      " public health facilities      17473\n",
      "                   hotels      13710\n",
      "         small commercial       8542\n",
      "\n",
      "Saved files:\n",
      " - artifacts/rows_per_city.csv\n",
      " - artifacts/rows_per_buildingtype_overall.csv\n",
      " - artifacts/rows_per_city_buildingtype.csv\n",
      " - artifacts/rows_pivot_city_by_buildingtype.csv\n"
     ]
    }
   ],
   "source": [
    "# === Step: Coverage summaries (City / BuildingType) ===\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA = Path(\"C:/Users/User/Desktop/ML/Project/solar-potential-analysis-github-setup/New_approach/dataset/cleaned_datasets/all_cities_weather_ready_train.parquet\")  # adjust if needed\n",
    "OUT  = Path(\"artifacts\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load minimal columns for speed/memory\n",
    "use_cols = [\"City\", \"BuildingType\"]\n",
    "df = pd.read_parquet(DATA, columns=use_cols)\n",
    "\n",
    "# Normalize dtypes (robust to mixed types)\n",
    "df[\"City\"] = df[\"City\"].astype(\"string\")\n",
    "df[\"BuildingType\"] = df[\"BuildingType\"].astype(\"string\")\n",
    "\n",
    "# 1) Rows per City\n",
    "city_counts = (\n",
    "    df[\"City\"]\n",
    "    .value_counts(dropna=False)\n",
    "    .rename_axis(\"City\")\n",
    "    .reset_index(name=\"row_count\")\n",
    "    .sort_values(\"row_count\", ascending=False)\n",
    ")\n",
    "city_counts.to_csv(OUT / \"rows_per_city.csv\", index=False)\n",
    "\n",
    "# 2) BuildingType counts overall (global)\n",
    "type_counts = (\n",
    "    df[\"BuildingType\"]\n",
    "    .value_counts(dropna=False)\n",
    "    .rename_axis(\"BuildingType\")\n",
    "    .reset_index(name=\"row_count\")\n",
    "    .sort_values(\"row_count\", ascending=False)\n",
    ")\n",
    "type_counts.to_csv(OUT / \"rows_per_buildingtype_overall.csv\", index=False)\n",
    "\n",
    "# 3) BuildingType counts within each City (City × BuildingType)\n",
    "city_type_counts = (\n",
    "    df.groupby([\"City\", \"BuildingType\"], dropna=False)\n",
    "      .size()\n",
    "      .reset_index(name=\"row_count\")\n",
    "      .sort_values([\"City\", \"row_count\"], ascending=[True, False])\n",
    ")\n",
    "city_type_counts.to_csv(OUT / \"rows_per_city_buildingtype.csv\", index=False)\n",
    "\n",
    "# Optional: a wide pivot (City × BuildingType) with zero fill for quick viewing\n",
    "pivot_ct = (\n",
    "    city_type_counts\n",
    "    .pivot(index=\"City\", columns=\"BuildingType\", values=\"row_count\")\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")\n",
    "pivot_ct.to_csv(OUT / \"rows_pivot_city_by_buildingtype.csv\")\n",
    "\n",
    "# Tiny preview so you can eyeball results in the notebook\n",
    "print(\"=== Top 10 cities by row count ===\")\n",
    "print(city_counts.head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\n=== Overall top 10 building types ===\")\n",
    "print(type_counts.head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\nSaved files:\")\n",
    "for p in [\n",
    "    \"rows_per_city.csv\",\n",
    "    \"rows_per_buildingtype_overall.csv\",\n",
    "    \"rows_per_city_buildingtype.csv\",\n",
    "    \"rows_pivot_city_by_buildingtype.csv\",\n",
    "]:\n",
    "    print(\" -\", (OUT / p).as_posix())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210c84f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 6,243,501\n",
      "Types total: 10\n",
      "Smallest K to reach coverage → 90%: 3, 95%: 4, 97%: 5, 99%: 7, 95.0%: 4\n",
      "\n",
      "=== Top 20 types (with cumulative %) ===\n",
      "             BuildingType  row_count    cum_pct\n",
      "single family residential    4023492  64.442882\n",
      "  multifamily residential    1420742  87.198416\n",
      "               commercial     354091  92.869770\n",
      "               industrial     150169  95.274975\n",
      "            public sector     146366  97.619268\n",
      "    peri-urban settlement      73521  98.796829\n",
      "                  schools      35395  99.363738\n",
      " public health facilities      17473  99.643597\n",
      "                   hotels      13710  99.863186\n",
      "         small commercial       8542 100.000000\n",
      "\n",
      "=== KEEP (coverage-based @ 95.0%) — 4 types; covers 95.27% ===\n",
      "             BuildingType  row_count\n",
      "single family residential    4023492\n",
      "  multifamily residential    1420742\n",
      "               commercial     354091\n",
      "               industrial     150169\n",
      "\n",
      "=== OTHER (coverage-based) — 6 types ===\n",
      "            BuildingType  row_count\n",
      "           public sector     146366\n",
      "   peri-urban settlement      73521\n",
      "                 schools      35395\n",
      "public health facilities      17473\n",
      "                  hotels      13710\n",
      "        small commercial       8542\n",
      "\n",
      "=== KEEP (min-support ≥ 5000) — 10 types; coverage 100.00% ===\n",
      "             BuildingType  row_count\n",
      "single family residential    4023492\n",
      "  multifamily residential    1420742\n",
      "               commercial     354091\n",
      "               industrial     150169\n",
      "            public sector     146366\n",
      "    peri-urban settlement      73521\n",
      "                  schools      35395\n",
      " public health facilities      17473\n",
      "                   hotels      13710\n",
      "         small commercial       8542\n",
      "\n",
      "=== OTHER (min-support) — 0 types ===\n",
      "Empty DataFrame\n",
      "Columns: [BuildingType, row_count]\n",
      "Index: []\n",
      "\n",
      "Saved:\n",
      " - artifacts/proposed_type_merge_95pct.csv\n",
      " - artifacts/proposed_type_merge_min5000.csv\n"
     ]
    }
   ],
   "source": [
    "# === BuildingType coverage & \"Other\" candidates (run me) ===\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- knobs you can tweak ---\n",
    "COVERAGE_TARGET = 95.0     # e.g., 90, 95, 97, 99\n",
    "MIN_SUPPORT     = 5000     # e.g., 2000, 10000\n",
    "\n",
    "# Try common locations for the counts file\n",
    "candidates = [\n",
    "    Path(\"artifacts/rows_per_buildingtype_overall.csv\"),\n",
    "    Path(\"rows_per_buildingtype_overall.csv\"),\n",
    "    Path(\"/mnt/data/rows_per_buildingtype_overall.csv\"),\n",
    "]\n",
    "for p in candidates:\n",
    "    if p.exists():\n",
    "        path = p\n",
    "        break\n",
    "else:\n",
    "    raise FileNotFoundError(\"Could not find rows_per_buildingtype_overall.csv in common locations.\")\n",
    "\n",
    "# Load and normalize columns\n",
    "tc = pd.read_csv(path)\n",
    "tc.columns = [c.strip() for c in tc.columns]\n",
    "# Guess column names if needed\n",
    "if \"BuildingType\" not in tc.columns:\n",
    "    tc = tc.rename(columns={tc.columns[0]: \"BuildingType\"})\n",
    "if \"row_count\" not in tc.columns:\n",
    "    count_col = [c for c in tc.columns if \"count\" in c.lower() or \"rows\" in c.lower()]\n",
    "    assert count_col, f\"Couldn't infer count column from: {tc.columns.tolist()}\"\n",
    "    tc = tc.rename(columns={count_col[0]: \"row_count\"})\n",
    "\n",
    "# Sort, cumulate, coverage\n",
    "tc = tc.sort_values(\"row_count\", ascending=False).reset_index(drop=True)\n",
    "total = int(tc[\"row_count\"].sum())\n",
    "tc[\"cum_rows\"] = tc[\"row_count\"].cumsum()\n",
    "tc[\"cum_pct\"]  = tc[\"cum_rows\"] / total * 100\n",
    "\n",
    "# Helper: smallest K types to hit a coverage %\n",
    "def k_for_coverage(df, pct):\n",
    "    idx = (df[\"cum_pct\"] >= pct).idxmax()  # first index crossing target\n",
    "    return int(idx) + 1                     # +1 because idx is 0-based\n",
    "\n",
    "k90 = k_for_coverage(tc, 90.0)\n",
    "k95 = k_for_coverage(tc, 95.0)\n",
    "k97 = k_for_coverage(tc, 97.0)\n",
    "k99 = k_for_coverage(tc, 99.0)\n",
    "kTT = k_for_coverage(tc, COVERAGE_TARGET)\n",
    "\n",
    "print(f\"Total rows: {total:,}\")\n",
    "print(f\"Types total: {tc.shape[0]}\")\n",
    "print(f\"Smallest K to reach coverage → 90%: {k90}, 95%: {k95}, 97%: {k97}, 99%: {k99}, {COVERAGE_TARGET:.1f}%: {kTT}\")\n",
    "\n",
    "# Coverage-based keep vs other\n",
    "keep_cov = tc.iloc[:kTT].copy()\n",
    "other_cov = tc.iloc[kTT:].copy()\n",
    "\n",
    "# Min-support keep vs other\n",
    "keep_min = tc[tc[\"row_count\"] >= MIN_SUPPORT].copy()\n",
    "other_min = tc[tc[\"row_count\"] <  MIN_SUPPORT].copy()\n",
    "\n",
    "# Previews\n",
    "print(\"\\n=== Top 20 types (with cumulative %) ===\")\n",
    "print(tc.loc[:19, [\"BuildingType\", \"row_count\", \"cum_pct\"]].to_string(index=False))\n",
    "\n",
    "print(f\"\\n=== KEEP (coverage-based @ {COVERAGE_TARGET:.1f}%) — {keep_cov.shape[0]} types; covers {keep_cov['cum_pct'].iloc[-1]:.2f}% ===\")\n",
    "print(keep_cov[[\"BuildingType\", \"row_count\"]].head(20).to_string(index=False))\n",
    "\n",
    "print(f\"\\n=== OTHER (coverage-based) — {other_cov.shape[0]} types ===\")\n",
    "print(other_cov[[\"BuildingType\", \"row_count\"]].tail(10).to_string(index=False))\n",
    "\n",
    "print(f\"\\n=== KEEP (min-support ≥ {MIN_SUPPORT}) — {keep_min.shape[0]} types; coverage {keep_min['row_count'].sum()/total*100:.2f}% ===\")\n",
    "print(keep_min[[\"BuildingType\", \"row_count\"]].head(20).to_string(index=False))\n",
    "\n",
    "print(f\"\\n=== OTHER (min-support) — {other_min.shape[0]} types ===\")\n",
    "print(other_min.sort_values('row_count').head(20)[[\"BuildingType\",\"row_count\"]].to_string(index=False))\n",
    "\n",
    "# Optional: write proposed mappings for both rules\n",
    "out_dir = Path(\"artifacts\"); out_dir.mkdir(parents=True, exist_ok=True)\n",
    "map_cov = tc[[\"BuildingType\"]].copy()\n",
    "map_cov[\"ProposedLabel\"] = map_cov[\"BuildingType\"].where(map_cov.index < kTT, \"Other\")\n",
    "map_cov.to_csv(out_dir / f\"proposed_type_merge_{COVERAGE_TARGET:.0f}pct.csv\", index=False)\n",
    "\n",
    "map_min = tc[[\"BuildingType\"]].copy()\n",
    "map_min[\"ProposedLabel\"] = map_min[\"BuildingType\"].where(tc[\"row_count\"] >= MIN_SUPPORT, \"Other\")\n",
    "map_min.to_csv(out_dir / f\"proposed_type_merge_min{MIN_SUPPORT}.csv\", index=False)\n",
    "\n",
    "# print(\"\\nSaved:\")\n",
    "# print(\" -\", (out_dir / f\"proposed_type_merge_{COVERAGE_TARGET:.0f}pct.csv\").as_posix())\n",
    "# print(\" -\", (out_dir / f\"proposed_type_merge_min{MIN_SUPPORT}.csv\").as_posix())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "321b548b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BuildingType_5 counts ===\n",
      "           BuildingType_5  row_count\n",
      "single family residential    4023492\n",
      "  multifamily residential    1420742\n",
      "               commercial     354091\n",
      "               industrial     150169\n",
      "                    Other     148641\n",
      "            public sector     146366\n",
      "\n",
      "=== SuperType counts ===\n",
      "  SuperType  row_count\n",
      "Residential    5517755\n",
      " Commercial     376343\n",
      "     Public     199234\n",
      " Industrial     150169\n",
      "\n",
      "Saved:\n",
      " - artifacts/kept_fine_types_97pct.csv\n",
      " - artifacts/supertype_map.csv\n",
      " - artifacts/counts_buildingtype5.csv\n",
      " - artifacts/counts_supertype.csv\n"
     ]
    }
   ],
   "source": [
    "# === Step: Freeze mappings + quick counts (lightweight) ===\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA = Path(\"C:/Users/User/Desktop/ML/Project/solar-potential-analysis-github-setup/New_approach/dataset/cleaned_datasets/all_cities_weather_ready_train.parquet\")  # adjust if needed\n",
    "OUT  = Path(\"artifacts\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- 1) Mappings we agreed on ---\n",
    "FIVE_TYPE_KEEP = {\n",
    "    \"single family residential\",\n",
    "    \"multifamily residential\",\n",
    "    \"commercial\",\n",
    "    \"industrial\",\n",
    "    \"public sector\",\n",
    "}\n",
    "# any BuildingType not in FIVE_TYPE_KEEP -> \"Other\"\n",
    "\n",
    "SUPERTYPE_MAP = {\n",
    "    # Residential\n",
    "    \"single family residential\": \"Residential\",\n",
    "    \"multifamily residential\": \"Residential\",\n",
    "    \"peri-urban settlement\": \"Residential\",\n",
    "    # Commercial\n",
    "    \"commercial\": \"Commercial\",\n",
    "    \"small commercial\": \"Commercial\",\n",
    "    \"hotels\": \"Commercial\",\n",
    "    # Industrial\n",
    "    \"industrial\": \"Industrial\",\n",
    "    # Public\n",
    "    \"public sector\": \"Public\",\n",
    "    \"schools\": \"Public\",\n",
    "    \"public health facilities\": \"Public\",\n",
    "}\n",
    "\n",
    "# Save mapping files for reproducibility\n",
    "pd.Series(sorted(FIVE_TYPE_KEEP)).to_csv(OUT / \"kept_fine_types_97pct.csv\", index=False, header=[\"BuildingType\"])\n",
    "pd.DataFrame(list(SUPERTYPE_MAP.items()), columns=[\"BuildingType\",\"SuperType\"]).to_csv(\n",
    "    OUT / \"supertype_map.csv\", index=False\n",
    ")\n",
    "\n",
    "# --- 2) Load only what we need (light memory) ---\n",
    "df = pd.read_parquet(DATA, columns=[\"City\", \"BuildingType\"])\n",
    "df[\"BuildingType\"] = df[\"BuildingType\"].astype(\"string\")\n",
    "df[\"City\"] = df[\"City\"].astype(\"string\")\n",
    "\n",
    "# --- 3) Derive columns (no dataset overwrite yet) ---\n",
    "df[\"BuildingType_5\"] = df[\"BuildingType\"].where(df[\"BuildingType\"].isin(FIVE_TYPE_KEEP), \"Other\")\n",
    "df[\"SuperType\"] = df[\"BuildingType\"].map(SUPERTYPE_MAP).astype(\"string\")\n",
    "\n",
    "# --- 4) Quick summaries + save ---\n",
    "type5_counts = df[\"BuildingType_5\"].value_counts().rename_axis(\"BuildingType_5\").reset_index(name=\"row_count\")\n",
    "super_counts = df[\"SuperType\"].value_counts().rename_axis(\"SuperType\").reset_index(name=\"row_count\")\n",
    "\n",
    "type5_counts.to_csv(OUT / \"counts_buildingtype5.csv\", index=False)\n",
    "super_counts.to_csv(OUT / \"counts_supertype.csv\", index=False)\n",
    "\n",
    "print(\"=== BuildingType_5 counts ===\")\n",
    "print(type5_counts.to_string(index=False))\n",
    "print(\"\\n=== SuperType counts ===\")\n",
    "print(super_counts.to_string(index=False))\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\" -\", (OUT / \"kept_fine_types_97pct.csv\").as_posix())\n",
    "print(\" -\", (OUT / \"supertype_map.csv\").as_posix())\n",
    "print(\" -\", (OUT / \"counts_buildingtype5.csv\").as_posix())\n",
    "print(\" -\", (OUT / \"counts_supertype.csv\").as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27fddd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Top-20 cities by row count ===\n",
      "            City  row_count\n",
      "      LagosState    1327213\n",
      "GreatDhakaRegion     623809\n",
      "     DarEsSalaam     515669\n",
      "     Mexico City     506631\n",
      "     SouthAfrica     411885\n",
      "          Manila     295984\n",
      "         Nairobi     269249\n",
      "         Colombo     265446\n",
      "           Accra     265113\n",
      "         Karachi     263704\n",
      "        Honduras     222819\n",
      "           Lagos     212267\n",
      "           Izmir     190384\n",
      "       Samarkand     189478\n",
      "          Panama     188460\n",
      "          Almaty     127614\n",
      "        Maldives      91424\n",
      "          Beirut      67686\n",
      "         Grenada      50476\n",
      "         Antigua      47929\n",
      "\n",
      "Q (min rows among top-20) = 47,929\n",
      "\n",
      "Saved:\n",
      " - artifacts/top20_cities_by_rows.csv\n",
      " - artifacts/top20_city_by_type_counts.csv\n"
     ]
    }
   ],
   "source": [
    "# === Step: Identify top-20 cities and Q, with 5-type coverage (no sampling) ===\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA = Path(\"C:/Users/User/Desktop/ML/Project/solar-potential-analysis-github-setup/New_approach/dataset/cleaned_datasets/all_cities_weather_ready_train.parquet\")\n",
    "OUT  = Path(\"artifacts\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- re-derive BuildingType_5 using the frozen mapping files you saved ---\n",
    "keep_path = OUT / \"kept_fine_types_97pct.csv\"\n",
    "kept = set(pd.read_csv(keep_path)[\"BuildingType\"].astype(str))\n",
    "\n",
    "# Load minimal columns\n",
    "df = pd.read_parquet(DATA, columns=[\"City\", \"BuildingType\"])\n",
    "df[\"City\"] = df[\"City\"].astype(\"string\")\n",
    "df[\"BuildingType\"] = df[\"BuildingType\"].astype(\"string\")\n",
    "df[\"BuildingType_5\"] = df[\"BuildingType\"].where(df[\"BuildingType\"].isin(kept), \"Other\")\n",
    "\n",
    "# 1) Top-20 cities by row count\n",
    "city_counts = (\n",
    "    df[\"City\"].value_counts()\n",
    "      .rename_axis(\"City\")\n",
    "      .reset_index(name=\"row_count\")\n",
    "      .sort_values(\"row_count\", ascending=False)\n",
    ")\n",
    "top20 = city_counts.head(20).reset_index(drop=True)\n",
    "\n",
    "# 2) Q = smallest row_count among the top-20\n",
    "Q = int(top20[\"row_count\"].min())\n",
    "\n",
    "# 3) Coverage table for just those top-20 cities (City × BuildingType_5)\n",
    "df_top20 = df[df[\"City\"].isin(top20[\"City\"])]\n",
    "city_type = (\n",
    "    df_top20.groupby([\"City\",\"BuildingType_5\"])\n",
    "            .size()\n",
    "            .reset_index(name=\"row_count\")\n",
    "            .sort_values([\"City\",\"row_count\"], ascending=[True, False])\n",
    ")\n",
    "\n",
    "# Save artifacts\n",
    "top20.to_csv(OUT / \"top20_cities_by_rows.csv\", index=False)\n",
    "city_type.to_csv(OUT / \"top20_city_by_type_counts.csv\", index=False)\n",
    "\n",
    "print(\"=== Top-20 cities by row count ===\")\n",
    "print(top20.to_string(index=False))\n",
    "print(f\"\\nQ (min rows among top-20) = {Q:,}\")\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\" -\", (OUT / \"top20_cities_by_rows.csv\").as_posix())\n",
    "print(\" -\", (OUT / \"top20_city_by_type_counts.csv\").as_posix())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4617b431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q = 47,929, FLOOR = 100, CEILING = 23965\n",
      "Saved: artifacts/top20_sampling_quotas.csv\n",
      "\n",
      "=== Preview: Accra ===\n",
      " City            BuildingType_5  available  quota\n",
      "Accra single family residential     226540  23965\n",
      "Accra                commercial      20413   9863\n",
      "Accra             public sector      12489   8430\n",
      "Accra                industrial       3150   3150\n",
      "Accra   multifamily residential       2521   2521\n",
      "\n",
      "Check sums (should be ≈ Q for each city):\n",
      "                City  quota\n",
      "0              Accra  47929\n",
      "1             Almaty  47929\n",
      "2            Antigua  47929\n",
      "3             Beirut  37278\n",
      "4            Colombo  47929\n",
      "5        DarEsSalaam  47929\n",
      "6   GreatDhakaRegion  47929\n",
      "7            Grenada  28153\n",
      "8           Honduras  47929\n",
      "9              Izmir  47929\n",
      "10           Karachi  47929\n",
      "11             Lagos  47929\n",
      "12        LagosState  47929\n",
      "13          Maldives  47929\n",
      "14            Manila  47929\n",
      "15       Mexico City  47929\n",
      "16           Nairobi  47929\n",
      "17            Panama  47929\n",
      "18         Samarkand  31720\n",
      "19       SouthAfrica  47929\n"
     ]
    }
   ],
   "source": [
    "# === Step: Compute top-20 per-type quotas (hybrid rule) ===\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "ART = Path(\"artifacts\")\n",
    "counts_path = ART / \"top20_city_by_type_counts.csv\"\n",
    "cities_path = ART / \"top20_cities_by_rows.csv\"\n",
    "out_path = ART / \"top20_sampling_quotas.csv\"\n",
    "\n",
    "# knobs\n",
    "Q = None                 # if None, infer from cities file (min of top-20); else set e.g., 47929\n",
    "FLOOR = 100              # min rows per present type (if available)\n",
    "CEILING = 23965          # max rows per type in a city (50% of Q)\n",
    "\n",
    "# load\n",
    "df = pd.read_csv(counts_path)          # columns: City, BuildingType_5, row_count\n",
    "top20 = pd.read_csv(cities_path)       # columns: City, row_count\n",
    "if Q is None:\n",
    "    Q = int(top20[\"row_count\"].min())  # infer\n",
    "assert \"City\" in df.columns and \"BuildingType_5\" in df.columns and \"row_count\" in df.columns\n",
    "\n",
    "# helper to allocate quotas for one city\n",
    "def allocate_city(city_df, Qcity, floor=100, ceiling=23965):\n",
    "    # city_df has columns: BuildingType_5, available=row_count\n",
    "    alloc = city_df.copy().rename(columns={\"row_count\":\"available\"})\n",
    "    alloc[\"quota\"] = 0\n",
    "\n",
    "    total_avail = int(alloc[\"available\"].sum())\n",
    "    if total_avail <= Qcity:\n",
    "        # Not enough rows to reach Q (unlikely for top-20); just take all\n",
    "        alloc[\"quota\"] = alloc[\"available\"]\n",
    "        return alloc\n",
    "\n",
    "    # 1) proportional backbone\n",
    "    prop = (Qcity * alloc[\"available\"] / total_avail).values\n",
    "    base = np.floor(prop).astype(int)  # start with floor of proportional\n",
    "    # 2) clip to availability & ceiling\n",
    "    cap = np.minimum(alloc[\"available\"].values, ceiling)\n",
    "    base = np.minimum(base, cap)\n",
    "    # 3) enforce floors (cannot exceed availability)\n",
    "    floors = np.minimum(alloc[\"available\"].values, floor)\n",
    "    base = np.maximum(base, floors)\n",
    "\n",
    "    alloc[\"quota\"] = base\n",
    "    diff = Qcity - int(alloc[\"quota\"].sum())\n",
    "\n",
    "    # convenience arrays for loop\n",
    "    quota = alloc[\"quota\"].values\n",
    "    avail = alloc[\"available\"].values\n",
    "\n",
    "    # 4) adjust to hit exact Qcity\n",
    "    # increment loop when we need more rows (diff > 0)\n",
    "    while diff > 0:\n",
    "        # room left = min(ceiling, availability) - quota\n",
    "        room = np.minimum(avail, ceiling) - quota\n",
    "        if room.sum() <= 0:\n",
    "            break  # cannot add more; stop slightly under Qcity\n",
    "        # distribute +1 to indices with largest room first (stable tie-breaker: by availability)\n",
    "        order = np.argsort(-room)  # descending room\n",
    "        progressed = False\n",
    "        for idx in order:\n",
    "            if room[idx] > 0:\n",
    "                quota[idx] += 1\n",
    "                diff -= 1\n",
    "                progressed = True\n",
    "                if diff == 0:\n",
    "                    break\n",
    "        if not progressed:\n",
    "            break\n",
    "\n",
    "    # decrement loop when we need to remove rows (diff < 0)\n",
    "    while diff < 0:\n",
    "        # removable = quota - floors (cannot go below floor or 0)\n",
    "        floors_now = np.minimum(avail, floor)\n",
    "        removable = quota - floors_now\n",
    "        if removable.sum() <= 0:\n",
    "            break  # cannot reduce further; stop slightly over Qcity\n",
    "        # take -1 from indices with largest quota first\n",
    "        order = np.argsort(-quota)  # biggest first\n",
    "        progressed = False\n",
    "        for idx in order:\n",
    "            if removable[idx] > 0:\n",
    "                quota[idx] -= 1\n",
    "                diff += 1\n",
    "                progressed = True\n",
    "                if diff == 0:\n",
    "                    break\n",
    "        if not progressed:\n",
    "            break\n",
    "\n",
    "    alloc[\"quota\"] = quota.astype(int)\n",
    "    return alloc\n",
    "\n",
    "# run allocation for each top-20 city\n",
    "quotas = []\n",
    "for city in top20[\"City\"].astype(str).tolist():\n",
    "    cdf = df[df[\"City\"] == city][[\"City\",\"BuildingType_5\",\"row_count\"]].copy()\n",
    "    if cdf.empty:\n",
    "        continue\n",
    "    alloc = allocate_city(cdf[[\"BuildingType_5\",\"row_count\"]].copy(), Q, FLOOR, CEILING)\n",
    "    alloc.insert(0, \"City\", city)\n",
    "    quotas.append(alloc)\n",
    "\n",
    "quotas_df = pd.concat(quotas, ignore_index=True)\n",
    "# sanity columns\n",
    "quotas_df[\"quota\"] = quotas_df[\"quota\"].astype(int)\n",
    "quotas_df[\"available\"] = quotas_df[\"available\"].astype(int)\n",
    "\n",
    "# save + preview\n",
    "quotas_df.to_csv(out_path, index=False)\n",
    "\n",
    "print(f\"Q = {Q:,}, FLOOR = {FLOOR}, CEILING = {CEILING}\")\n",
    "print(\"Saved:\", out_path.as_posix())\n",
    "\n",
    "# show 10-line preview (first city alphabetical)\n",
    "first_city = sorted(quotas_df['City'].unique())[0]\n",
    "print(f\"\\n=== Preview: {first_city} ===\")\n",
    "print(quotas_df[quotas_df[\"City\"]==first_city]\n",
    "      .sort_values(\"quota\", ascending=False)\n",
    "      .to_string(index=False))\n",
    "print(\"\\nCheck sums (should be ≈ Q for each city):\")\n",
    "print(quotas_df.groupby(\"City\")[\"quota\"].sum().reset_index().head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c80950e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q = 47,929, FLOOR = 100, BASE_CEILING = 23965\n",
      "Saved: artifacts/top20_sampling_quotas_adaptive.csv\n",
      "\n",
      "=== Cities not hitting Q before (if any) and after ===\n",
      "           new_quota_sum  old_quota_sum  delta\n",
      "City                                          \n",
      "Beirut             47929          37278  10651\n",
      "Grenada            47929          28153  19776\n",
      "Samarkand          47929          31720  16209\n"
     ]
    }
   ],
   "source": [
    "# === Patch: Recompute quotas with adaptive ceiling per city ===\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "ART = Path(\"artifacts\")\n",
    "counts_path = ART / \"top20_city_by_type_counts.csv\"\n",
    "cities_path = ART / \"top20_cities_by_rows.csv\"\n",
    "out_path = ART / \"top20_sampling_quotas_adaptive.csv\"\n",
    "\n",
    "# knobs\n",
    "Q = None            # infer from top-20 min\n",
    "FLOOR = 100\n",
    "BASE_CEILING = 23965   # start at 50% of Q; will relax if needed up to Q\n",
    "\n",
    "df = pd.read_csv(counts_path)            # City, BuildingType_5, row_count\n",
    "top20 = pd.read_csv(cities_path)         # City, row_count\n",
    "if Q is None:\n",
    "    Q = int(top20[\"row_count\"].min())\n",
    "\n",
    "def allocate_city_adaptive(city_df, Qcity, floor=100, base_ceiling=23965):\n",
    "    alloc = city_df.copy().rename(columns={\"row_count\": \"available\"})\n",
    "    alloc[\"quota\"] = 0\n",
    "    total_avail = int(alloc[\"available\"].sum())\n",
    "    if total_avail <= Qcity:\n",
    "        alloc[\"quota\"] = alloc[\"available\"]\n",
    "        return alloc\n",
    "\n",
    "    # Start from base ceiling; if infeasible, relax upward towards Q\n",
    "    ceiling = base_ceiling\n",
    "    # Ensure feasibility: sum(min(avail, ceiling)) >= Q\n",
    "    while np.minimum(alloc[\"available\"].values, ceiling).sum() < Qcity and ceiling < Qcity:\n",
    "        # relax ceiling in chunks: try to close the gap roughly in 2–3 steps\n",
    "        gap = Qcity - int(np.minimum(alloc[\"available\"].values, ceiling).sum())\n",
    "        ceiling = min(Qcity, ceiling + max(1000, gap // 2))\n",
    "\n",
    "    # Proportional backbone\n",
    "    prop = (Qcity * alloc[\"available\"] / total_avail).values\n",
    "    base = np.floor(prop).astype(int)\n",
    "\n",
    "    cap = np.minimum(alloc[\"available\"].values, ceiling)\n",
    "    base = np.minimum(base, cap)\n",
    "    floors = np.minimum(alloc[\"available\"].values, floor)\n",
    "    base = np.maximum(base, floors)\n",
    "\n",
    "    quota = base.copy()\n",
    "    avail = alloc[\"available\"].values\n",
    "    diff = Qcity - int(quota.sum())\n",
    "\n",
    "    # Grow if short\n",
    "    while diff > 0:\n",
    "        room = np.minimum(avail, ceiling) - quota\n",
    "        if room.sum() <= 0:\n",
    "            break\n",
    "        order = np.argsort(-room)\n",
    "        progressed = False\n",
    "        for idx in order:\n",
    "            if room[idx] > 0:\n",
    "                quota[idx] += 1\n",
    "                diff -= 1\n",
    "                progressed = True\n",
    "                if diff == 0:\n",
    "                    break\n",
    "        if not progressed:\n",
    "            break\n",
    "\n",
    "    # Shrink if over\n",
    "    while diff < 0:\n",
    "        floors_now = np.minimum(avail, floor)\n",
    "        removable = quota - floors_now\n",
    "        if removable.sum() <= 0:\n",
    "            break\n",
    "        order = np.argsort(-quota)\n",
    "        progressed = False\n",
    "        for idx in order:\n",
    "            if removable[idx] > 0:\n",
    "                quota[idx] -= 1\n",
    "                diff += 1\n",
    "                progressed = True\n",
    "                if diff == 0:\n",
    "                    break\n",
    "        if not progressed:\n",
    "            break\n",
    "\n",
    "    out = alloc.copy()\n",
    "    out[\"quota\"] = quota.astype(int)\n",
    "    out[\"ceiling_used\"] = ceiling\n",
    "    return out\n",
    "\n",
    "# Identify cities underfilled with the original quotas (if you saved them)\n",
    "try:\n",
    "    old_q = pd.read_csv(ART / \"top20_sampling_quotas.csv\")\n",
    "    old_sums = old_q.groupby(\"City\")[\"quota\"].sum().rename(\"old_quota_sum\")\n",
    "except Exception:\n",
    "    old_sums = None\n",
    "\n",
    "# Recompute with adaptive ceiling\n",
    "rows = []\n",
    "for city, cdf in df.groupby(\"City\", sort=False):\n",
    "    alloc = allocate_city_adaptive(cdf[[\"BuildingType_5\",\"row_count\"]], Q, FLOOR, BASE_CEILING)\n",
    "    alloc.insert(0, \"City\", city)\n",
    "    rows.append(alloc)\n",
    "\n",
    "new_q = pd.concat(rows, ignore_index=True)\n",
    "new_q.to_csv(out_path, index=False)\n",
    "\n",
    "new_sums = new_q.groupby(\"City\")[\"quota\"].sum().rename(\"new_quota_sum\")\n",
    "report = new_sums.to_frame()\n",
    "if old_sums is not None:\n",
    "    report = report.join(old_sums, how=\"left\")\n",
    "    report[\"delta\"] = report[\"new_quota_sum\"] - report[\"old_quota_sum\"]\n",
    "\n",
    "print(f\"Q = {Q:,}, FLOOR = {FLOOR}, BASE_CEILING = {BASE_CEILING}\")\n",
    "print(\"Saved:\", out_path.as_posix())\n",
    "\n",
    "print(\"\\n=== Cities not hitting Q before (if any) and after ===\")\n",
    "print(report[(report[\"new_quota_sum\"] != Q) | (report.get(\"old_quota_sum\", pd.Series(dtype=int)) != Q)].sort_index().to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f63f7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-city sampled counts (expect constant Q):\n",
      "            City  sampled\n",
      "           Accra    47929\n",
      "          Almaty    47929\n",
      "         Antigua    47929\n",
      "          Beirut    47929\n",
      "         Colombo    47929\n",
      "     DarEsSalaam    47929\n",
      "GreatDhakaRegion    47929\n",
      "         Grenada    47929\n",
      "        Honduras    47929\n",
      "           Izmir    47929\n",
      "         Karachi    47929\n",
      "           Lagos    47929\n",
      "      LagosState    47929\n",
      "        Maldives    47929\n",
      "          Manila    47929\n",
      "     Mexico City    47929\n",
      "         Nairobi    47929\n",
      "          Panama    47929\n",
      "       Samarkand    47929\n",
      "     SouthAfrica    47929\n",
      "\n",
      "Max absolute diff vs quota: 0\n",
      "\n",
      "Saved sampled row indices to: artifacts/top20_sampled_rowidx.csv\n"
     ]
    }
   ],
   "source": [
    "# === Step: Sample row indices per (City, BuildingType_5) using adaptive quotas ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "SEED = 42\n",
    "rng = np.random.default_rng(SEED)\n",
    "DATA = Path(\"C:/Users/User/Desktop/ML/Project/solar-potential-analysis-github-setup/New_approach/dataset/cleaned_datasets/all_cities_weather_ready_train.parquet\")\n",
    "ART  = Path(\"artifacts\"); ART.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Inputs from previous steps\n",
    "quotas_path = ART / \"top20_sampling_quotas_adaptive.csv\"   # City, BuildingType_5, available, quota, ceiling_used\n",
    "keep_types   = set(pd.read_csv(ART / \"kept_fine_types_97pct.csv\")[\"BuildingType\"].astype(str))\n",
    "\n",
    "# Load minimal columns to keep memory light\n",
    "df = pd.read_parquet(DATA, columns=[\"City\",\"BuildingType\"])\n",
    "df[\"City\"] = df[\"City\"].astype(\"string\")\n",
    "df[\"BuildingType\"] = df[\"BuildingType\"].astype(\"string\")\n",
    "# Derive 5-type label\n",
    "df[\"BuildingType_5\"] = df[\"BuildingType\"].where(df[\"BuildingType\"].isin(keep_types), \"Other\")\n",
    "\n",
    "# Load quotas\n",
    "q = pd.read_csv(quotas_path)\n",
    "q[\"City\"] = q[\"City\"].astype(\"string\")\n",
    "q[\"BuildingType_5\"] = q[\"BuildingType_5\"].astype(\"string\")\n",
    "\n",
    "# Filter dataframe to top-20 cities only (faster sampling)\n",
    "top20_cities = q[\"City\"].unique().tolist()\n",
    "df20 = df[df[\"City\"].isin(top20_cities)].copy()\n",
    "\n",
    "# Sample per (City, Type5)\n",
    "samples = []\n",
    "for _, row in q.iterrows():\n",
    "    c, t, n = row[\"City\"], row[\"BuildingType_5\"], int(row[\"quota\"])\n",
    "    idx = df20.index[(df20[\"City\"] == c) & (df20[\"BuildingType_5\"] == t)].to_numpy()\n",
    "    if len(idx) == 0:\n",
    "        continue  # absent type in this city (quota should be 0 in that case)\n",
    "    # safe guard: cannot sample more than available (allocator already enforced, but just in case)\n",
    "    n = min(n, len(idx))\n",
    "    take = rng.choice(idx, size=n, replace=False)\n",
    "    samples.append(pd.DataFrame({\"City\": c, \"BuildingType_5\": t, \"row_idx\": take}))\n",
    "\n",
    "sampled = pd.concat(samples, ignore_index=True)\n",
    "\n",
    "# Sanity: per-city sums should all equal Q\n",
    "per_city = sampled.groupby(\"City\").size().rename(\"sampled\").reset_index()\n",
    "print(\"Per-city sampled counts (expect constant Q):\")\n",
    "print(per_city.to_string(index=False))\n",
    "\n",
    "# Sanity: match the quotas\n",
    "check = (sampled.groupby([\"City\",\"BuildingType_5\"]).size()\n",
    "         .rename(\"sampled\")\n",
    "         .reset_index()\n",
    "         .merge(q[[\"City\",\"BuildingType_5\",\"quota\"]], on=[\"City\",\"BuildingType_5\"], how=\"right\")\n",
    "        )\n",
    "check[\"diff\"] = check[\"sampled\"].fillna(0).astype(int) - check[\"quota\"].astype(int)\n",
    "print(\"\\nMax absolute diff vs quota:\", int(check[\"diff\"].abs().max()))\n",
    "\n",
    "# Save IDs\n",
    "out_ids = ART / \"top20_sampled_rowidx.csv\"\n",
    "sampled.sort_values(\"row_idx\").to_csv(out_ids, index=False)\n",
    "print(\"\\nSaved sampled row indices to:\", out_ids.as_posix())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62a1ed7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:/Users/User/Desktop/ML/Project/solar-potential-analysis-github-setup/New_approach/dataset/cleaned_datasets/top20_balanced_sample.parquet Rows: 958580\n",
      "\n",
      "Per-city counts (should all be 47,929):\n",
      "City\n",
      "Accra               47929\n",
      "Almaty              47929\n",
      "Antigua             47929\n",
      "Beirut              47929\n",
      "Colombo             47929\n",
      "DarEsSalaam         47929\n",
      "GreatDhakaRegion    47929\n",
      "Grenada             47929\n",
      "Honduras            47929\n",
      "Izmir               47929\n",
      "Karachi             47929\n",
      "Lagos               47929\n",
      "LagosState          47929\n",
      "Maldives            47929\n",
      "Manila              47929\n",
      "Mexico City         47929\n",
      "Nairobi             47929\n",
      "Panama              47929\n",
      "Samarkand           47929\n",
      "SouthAfrica         47929\n",
      "\n",
      "BuildingType_5 counts (overall):\n",
      "BuildingType_5\n",
      "single family residential    442224\n",
      "multifamily residential      193430\n",
      "commercial                   125447\n",
      "public sector                 76208\n",
      "industrial                    71843\n",
      "Other                         49428\n"
     ]
    }
   ],
   "source": [
    "# === Step: Materialize the sampled dataset (parquet) ===\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA = Path(\"C:/Users/User/Desktop/ML/Project/solar-potential-analysis-github-setup/New_approach/dataset/cleaned_datasets/all_cities_weather_ready_train.parquet\")\n",
    "ART  = Path(\"artifacts\")\n",
    "OUT  = Path(\"C:/Users/User/Desktop/ML/Project/solar-potential-analysis-github-setup/New_approach/dataset/cleaned_datasets/top20_balanced_sample.parquet\")\n",
    "\n",
    "# Load sampled row indices\n",
    "ids = pd.read_csv(ART / \"top20_sampled_rowidx.csv\")  # City, BuildingType_5, row_idx\n",
    "\n",
    "# Load full columns for just those rows (filter by index)\n",
    "# NOTE: row_idx corresponds to the original row order in the parquet.\n",
    "df_full = pd.read_parquet(DATA)  # if memory is tight, we can chunk, but try full first\n",
    "sampled = df_full.iloc[ids[\"row_idx\"].values].copy()\n",
    "\n",
    "# Optional: carry over BuildingType_5 from IDs (handy for quick checks)\n",
    "sampled[\"BuildingType_5\"] = ids[\"BuildingType_5\"].values\n",
    "sampled[\"City\"] = ids[\"City\"].values  # ensures consistency if City dtype differs\n",
    "\n",
    "# Save compact parquet\n",
    "sampled.to_parquet(OUT, index=False)\n",
    "print(\"Saved:\", OUT.as_posix(), \"Rows:\", len(sampled))\n",
    "\n",
    "# Quick sanity: counts by City\n",
    "print(\"\\nPer-city counts (should all be 47,929):\")\n",
    "print(sampled[\"City\"].value_counts().sort_index().to_string())\n",
    "\n",
    "# Quick sanity: 5-type distribution overall\n",
    "if \"BuildingType_5\" in sampled.columns:\n",
    "    print(\"\\nBuildingType_5 counts (overall):\")\n",
    "    print(sampled[\"BuildingType_5\"].value_counts().to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c82aee9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (958580, 11)\n",
      "Cities (should be 20): 20\n",
      "5-type labels: ['multifamily residential', 'public sector', 'single family residential', 'commercial', 'industrial', 'Other']\n",
      "\n",
      "=== GroupKFold by City (inspection) ===\n",
      "Fold 1: train=766,864  valid=191,716  valid_cities=4 → Colombo, Izmir, Manila, SouthAfrica\n",
      "Fold 2: train=766,864  valid=191,716  valid_cities=4 → Beirut, Honduras, Maldives, Samarkand\n",
      "Fold 3: train=766,864  valid=191,716  valid_cities=4 → Antigua, Grenada, LagosState, Panama\n",
      "Fold 4: train=766,864  valid=191,716  valid_cities=4 → Almaty, GreatDhakaRegion, Lagos, Nairobi\n",
      "Fold 5: train=766,864  valid=191,716  valid_cities=4 → Accra, DarEsSalaam, Karachi, Mexico City\n"
     ]
    }
   ],
   "source": [
    "# === Step: Define grouped CV on the balanced dataset (inspect only) ===\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "DATA = Path(\"C:/Users/User/Desktop/ML/Project/solar-potential-analysis-github-setup/New_approach/dataset/cleaned_datasets/top20_balanced_sample.parquet\")  # adjust if your path differs\n",
    "\n",
    "# Load only what we need for splitting/inspection\n",
    "cols = [\"City\",\"BuildingType_5\",\"kWh_per_m2\",\n",
    "        \"tilt\",\"tilt2\",\"tilt_sin\",\"tilt_cos\",\n",
    "        \"GHI_kWh_per_m2_day\",\"AvgTemp_C\",\"ClearnessIndex\",\"Precip_mm_per_day\"]\n",
    "df = pd.read_parquet(DATA, columns=[c for c in cols if c in pd.read_parquet(DATA).columns])\n",
    "\n",
    "# Basic sanity\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Cities (should be 20):\", df[\"City\"].nunique())\n",
    "print(\"5-type labels:\", df[\"BuildingType_5\"].unique().tolist())\n",
    "\n",
    "# Set up GroupKFold by City (5 folds)\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "groups = df[\"City\"].astype(str)\n",
    "\n",
    "fold_summary = []\n",
    "for i, (tr, te) in enumerate(gkf.split(df, df[\"kWh_per_m2\"], groups=groups), 1):\n",
    "    te_cities = df.iloc[te][\"City\"].unique().tolist()\n",
    "    fold_summary.append({\n",
    "        \"fold\": i,\n",
    "        \"n_rows_train\": len(tr),\n",
    "        \"n_rows_valid\": len(te),\n",
    "        \"n_cities_valid\": len(te_cities),\n",
    "        \"valid_cities\": \", \".join(sorted(te_cities))\n",
    "    })\n",
    "\n",
    "print(\"\\n=== GroupKFold by City (inspection) ===\")\n",
    "for row in fold_summary:\n",
    "    print(f\"Fold {row['fold']}: train={row['n_rows_train']:,}  valid={row['n_rows_valid']:,}  \"\n",
    "          f\"valid_cities={row['n_cities_valid']} → {row['valid_cities']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c95b7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figures:\n",
      " - artifacts/imbalance_pareto_buildingtypes.png\n",
      " - artifacts/imbalance_city_counts_top30.png\n",
      " - artifacts/imbalance_city_size_hist.png\n",
      " - artifacts/imbalance_city_by_type_heatmap.png\n",
      "\n",
      "Saved tables:\n",
      " - artifacts/imbalance_type_counts_pareto.csv\n",
      " - artifacts/imbalance_city_counts.csv\n",
      " - artifacts/imbalance_city_by_type_pivot.csv\n"
     ]
    }
   ],
   "source": [
    "# === Imbalance visuals: Pareto (types), Top-30 cities, City×Type Heatmap ===\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- paths ----------\n",
    "DATA = Path(\"C:/Users/User/Desktop/ML/Project/solar-potential-analysis-github-setup/New_approach/dataset/cleaned_datasets/all_cities_weather_ready_train.parquet\")\n",
    "ART  = Path(\"artifacts\"); ART.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- load + 5-type mapping ----------\n",
    "df = pd.read_parquet(DATA, columns=[\"City\",\"BuildingType\"])\n",
    "df[\"City\"] = df[\"City\"].astype(\"string\")\n",
    "df[\"BuildingType\"] = df[\"BuildingType\"].astype(\"string\")\n",
    "\n",
    "kept = set(pd.read_csv(ART/\"kept_fine_types_97pct.csv\")[\"BuildingType\"].astype(str))\n",
    "df[\"BuildingType_5\"] = df[\"BuildingType\"].where(df[\"BuildingType\"].isin(kept), \"Other\")\n",
    "\n",
    "# ---------- 1) Pareto of original 10 types ----------\n",
    "type_counts = (\n",
    "    df[\"BuildingType\"]\n",
    "      .value_counts()\n",
    "      .rename_axis(\"BuildingType\")\n",
    "      .reset_index(name=\"row_count\")\n",
    ")\n",
    "type_counts[\"cum_pct\"] = 100 * type_counts[\"row_count\"].cumsum() / type_counts[\"row_count\"].sum()\n",
    "type_counts.to_csv(ART/\"imbalance_type_counts_pareto.csv\", index=False)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "x = np.arange(len(type_counts))\n",
    "plt.bar(x, type_counts[\"row_count\"].values)  # bar for counts\n",
    "# cumulative line (secondary axis)\n",
    "ax1 = plt.gca()\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(x, type_counts[\"cum_pct\"].values, marker=\"o\")\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(type_counts[\"BuildingType\"].tolist(), rotation=30, ha=\"right\")\n",
    "ax1.set_ylabel(\"Rows\")\n",
    "ax2.set_ylabel(\"Cumulative %\")\n",
    "plt.title(\"Pareto of Building Types (original labels)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(ART/\"imbalance_pareto_buildingtypes.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# ---------- 2) City counts (Top-30) ----------\n",
    "city_counts = (\n",
    "    df[\"City\"].value_counts()\n",
    "      .rename_axis(\"City\")\n",
    "      .reset_index(name=\"row_count\")\n",
    ")\n",
    "city_counts.to_csv(ART/\"imbalance_city_counts.csv\", index=False)\n",
    "\n",
    "topN = 30\n",
    "cc30 = city_counts.head(topN)\n",
    "plt.figure(figsize=(10,7))\n",
    "x = np.arange(len(cc30))\n",
    "plt.barh(x, cc30[\"row_count\"].values)\n",
    "plt.yticks(x, cc30[\"City\"].tolist())\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Rows\")\n",
    "plt.title(f\"Top-{topN} Cities by Row Count\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(ART/\"imbalance_city_counts_top30.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# also a histogram (overall spread of city sizes)\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(city_counts[\"row_count\"].values, bins=50)\n",
    "plt.xlabel(\"Rows per City\")\n",
    "plt.ylabel(\"Number of Cities\")\n",
    "plt.title(\"Distribution of City Sizes (All Cities)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(ART/\"imbalance_city_size_hist.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# ---------- 3) City × BuildingType_5 heatmap (no masking) ----------\n",
    "# use top-40 cities to keep the figure readable\n",
    "topC = city_counts[\"City\"].head(40).tolist()\n",
    "pivot = (df[df[\"City\"].isin(topC)]\n",
    "         .pivot_table(index=\"City\", columns=\"BuildingType_5\", values=\"BuildingType\",\n",
    "                      aggfunc=\"count\", fill_value=0))\n",
    "pivot = pivot.reindex(index=topC)  # keep order\n",
    "pivot.to_csv(ART/\"imbalance_city_by_type_pivot.csv\")\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "# simple image plot (no seaborn, no masking)\n",
    "plt.imshow(pivot.values, aspect=\"auto\")\n",
    "plt.xticks(np.arange(pivot.shape[1]), pivot.columns.tolist(), rotation=30, ha=\"right\")\n",
    "plt.yticks(np.arange(pivot.shape[0]), pivot.index.tolist())\n",
    "plt.colorbar(label=\"Row count\")\n",
    "plt.title(\"City × BuildingType_5 (Top-40 Cities)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(ART/\"imbalance_city_by_type_heatmap.png\", dpi=220)\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved figures:\")\n",
    "print(\" - artifacts/imbalance_pareto_buildingtypes.png\")\n",
    "print(\" - artifacts/imbalance_city_counts_top30.png\")\n",
    "print(\" - artifacts/imbalance_city_size_hist.png\")\n",
    "print(\" - artifacts/imbalance_city_by_type_heatmap.png\")\n",
    "print(\"\\nSaved tables:\")\n",
    "print(\" - artifacts/imbalance_type_counts_pareto.csv\")\n",
    "print(\" - artifacts/imbalance_city_counts.csv\")\n",
    "print(\" - artifacts/imbalance_city_by_type_pivot.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03108ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_47412\\1919117730.py:99: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n",
      "  pivot = (sub.pivot_table(index=\"City\", columns=\"BuildingType_5\", values=\"quota\", aggfunc=\"sum\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved visuals:\n",
      " - artifacts/viz_city_imbalance_top40_with_cutoff.png\n",
      " - artifacts/viz_type_pareto_97pct.png\n",
      " - artifacts/viz_quota_stacked_example_cities.png\n"
     ]
    }
   ],
   "source": [
    "# === Imbalance handling: slide visuals pack (cities + building types + quotas) ===\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- paths ----------\n",
    "DATA = Path(\"C:/Users/User/Desktop/ML/Project/solar-potential-analysis-github-setup/New_approach/dataset/cleaned_datasets/top20_balanced_sample.parquet\")\n",
    "ART  = Path(\"artifacts\"); ART.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Inputs produced earlier\n",
    "keep_types_path   = ART / \"kept_fine_types_97pct.csv\"         # 5 kept fine types\n",
    "top20_path        = ART / \"top20_cities_by_rows.csv\"           # top-20 cities with counts\n",
    "quotas_adapt_path = ART / \"top20_sampling_quotas_adaptive.csv\" # quotas per City × BuildingType_5\n",
    "\n",
    "# Choose a few illustrative cities for stacked quotas (edit if you want different ones)\n",
    "EXAMPLE_CITIES = [\"Accra\", \"Beirut\", \"Almaty\"]  # diverse mix; tweak as you like\n",
    "\n",
    "# ---------- load base data ----------\n",
    "df = pd.read_parquet(DATA, columns=[\"City\",\"BuildingType\"])\n",
    "df[\"City\"] = df[\"City\"].astype(\"string\")\n",
    "df[\"BuildingType\"] = df[\"BuildingType\"].astype(\"string\")\n",
    "\n",
    "kept = set(pd.read_csv(keep_types_path)[\"BuildingType\"].astype(str))\n",
    "df[\"BuildingType_5\"] = df[\"BuildingType\"].where(df[\"BuildingType\"].isin(kept), \"Other\")\n",
    "\n",
    "top20 = pd.read_csv(top20_path)  # City, row_count\n",
    "Q = int(top20[\"row_count\"].min())\n",
    "\n",
    "# ---------- 1) City imbalance & top-20 cutoff ----------\n",
    "city_counts = (\n",
    "    df[\"City\"].value_counts()\n",
    "      .rename_axis(\"City\")\n",
    "      .reset_index(name=\"row_count\")\n",
    ")\n",
    "\n",
    "# mark top-20 cutoff\n",
    "cutoff_count = int(city_counts.iloc[19][\"row_count\"]) if len(city_counts) >= 20 else int(city_counts[\"row_count\"].min())\n",
    "\n",
    "plt.figure(figsize=(11,6))\n",
    "x = np.arange(len(city_counts.head(40)))\n",
    "plt.bar(x, city_counts[\"row_count\"].head(40).values)\n",
    "plt.xticks(x, city_counts[\"City\"].head(40).tolist(), rotation=30, ha=\"right\")\n",
    "plt.axhline(cutoff_count, linestyle=\"--\")\n",
    "plt.text(0.5, cutoff_count*1.02, f\"Top-20 cutoff ≈ {cutoff_count:,} rows (Q source)\", va=\"bottom\")\n",
    "plt.title(\"City Imbalance — Row Counts (Top 40) with Top-20 Cutoff\")\n",
    "plt.ylabel(\"Rows per City\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(ART/\"viz_city_imbalance_top40_with_cutoff.png\", dpi=220)\n",
    "plt.close()\n",
    "\n",
    "# ---------- 2) Building-type Pareto (original labels) with 97% marker ----------\n",
    "type_counts = (\n",
    "    df[\"BuildingType\"].value_counts()\n",
    "      .rename_axis(\"BuildingType\")\n",
    "      .reset_index(name=\"row_count\")\n",
    ")\n",
    "type_counts[\"cum_pct\"] = 100 * type_counts[\"row_count\"].cumsum() / type_counts[\"row_count\"].sum()\n",
    "\n",
    "# find smallest K to reach 97%\n",
    "k97 = int((type_counts[\"cum_pct\"] <= 97.0).sum()) + 1 if (type_counts[\"cum_pct\"] > 97.0).any() else len(type_counts)\n",
    "\n",
    "plt.figure(figsize=(11,6))\n",
    "x = np.arange(len(type_counts))\n",
    "# counts as bars\n",
    "plt.bar(x, type_counts[\"row_count\"].values)\n",
    "# cumulative % as line using twin axis\n",
    "ax1 = plt.gca()\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(x, type_counts[\"cum_pct\"].values, marker=\"o\")\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(type_counts[\"BuildingType\"].tolist(), rotation=30, ha=\"right\")\n",
    "ax1.set_ylabel(\"Rows\")\n",
    "ax2.set_ylabel(\"Cumulative %\")\n",
    "# marker at 97%\n",
    "# position at boundary index (clip within range)\n",
    "mark_idx = min(k97-1, len(type_counts)-1)\n",
    "ax2.axhline(97.0, linestyle=\"--\")\n",
    "ax2.text(max(0, mark_idx-0.5), 97.5, \"97% coverage → keep 5 fine types\", va=\"bottom\")\n",
    "plt.title(\"Building-Type Pareto (Original Labels) with 97% Coverage Marker\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(ART/\"viz_type_pareto_97pct.png\", dpi=220)\n",
    "plt.close()\n",
    "\n",
    "# ---------- 3) Within-city stacked quotas for a few cities ----------\n",
    "q = pd.read_csv(quotas_adapt_path)  # City, BuildingType_5, available, quota, ceiling_used\n",
    "order_types = [\n",
    "    \"single family residential\",\n",
    "    \"multifamily residential\",\n",
    "    \"commercial\",\n",
    "    \"industrial\",\n",
    "    \"public sector\",\n",
    "    \"Other\",\n",
    "]\n",
    "q[\"BuildingType_5\"] = pd.Categorical(q[\"BuildingType_5\"], categories=order_types, ordered=True)\n",
    "\n",
    "sub = q[q[\"City\"].isin(EXAMPLE_CITIES)].copy()\n",
    "# ensure consistent order: the order of EXAMPLE_CITIES\n",
    "city_order = [c for c in EXAMPLE_CITIES if c in sub[\"City\"].unique().tolist()]\n",
    "pivot = (sub.pivot_table(index=\"City\", columns=\"BuildingType_5\", values=\"quota\", aggfunc=\"sum\")\n",
    "           .reindex(index=city_order).reindex(columns=order_types))\n",
    "pivot = pivot.fillna(0)\n",
    "\n",
    "plt.figure(figsize=(11,4.5))\n",
    "x = np.arange(len(pivot.index))\n",
    "bottom = np.zeros(len(pivot.index))\n",
    "for t in pivot.columns:\n",
    "    vals = pivot[t].values\n",
    "    plt.bar(x, vals, bottom=bottom)\n",
    "    bottom = bottom + vals\n",
    "plt.xticks(x, pivot.index.tolist(), rotation=0)\n",
    "plt.ylabel(\"Quota per City (rows)\")\n",
    "plt.title(\"Within-City Sampling Quotas by BuildingType_5 (Examples)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(ART/\"viz_quota_stacked_example_cities.png\", dpi=220)\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved visuals:\")\n",
    "print(\" - artifacts/viz_city_imbalance_top40_with_cutoff.png\")\n",
    "print(\" - artifacts/viz_type_pareto_97pct.png\")\n",
    "print(\" - artifacts/viz_quota_stacked_example_cities.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
