{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74e897b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded dataset: (249428, 12)\n",
      "BuildingType\n",
      "commercial                   40000\n",
      "industrial                   40000\n",
      "multifamily residential      40000\n",
      "public sector                40000\n",
      "single family residential    40000\n",
      "peri-urban settlement        16960\n",
      "schools                      14596\n",
      "public health facilities      8009\n",
      "hotels                        7493\n",
      "small commercial              2370\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# === Load balanced-by-type dataset ===\n",
    "DATA = Path(\"/Users/thetsusann/Documents/ML/Energy404---Rooftop-Solar-Potential/New_approach/dataset/cleaned_datasets/top20_balanced_by_type.parquet\")\n",
    "df = pd.read_parquet(DATA)\n",
    "\n",
    "print(\"âœ… Loaded dataset:\", df.shape)\n",
    "print(df[\"BuildingType\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51e58e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Feature sets ===\n",
    "TARGET = \"kWh_per_m2\"\n",
    "CAT = [\"BuildingType\"]\n",
    "NUM = [\n",
    "    \"tilt\",\"tilt2\",\"tilt_sin\",\"tilt_cos\",\n",
    "    \"GHI_kWh_per_m2_day\",\"AvgTemp_C\",\n",
    "    \"ClearnessIndex\",\"Precip_mm_per_day\"\n",
    "]\n",
    "\n",
    "X = df[NUM + CAT].copy()\n",
    "y = df[TARGET].copy()\n",
    "\n",
    "# Categorical conversion for LightGBM\n",
    "for c in CAT:\n",
    "    X[c] = X[c].astype(\"category\")\n",
    "\n",
    "# Encode categorical for XGB\n",
    "X_xgb = X.copy()\n",
    "X_xgb[\"BuildingType\"] = X_xgb[\"BuildingType\"].cat.codes\n",
    "\n",
    "# Log-transform the target\n",
    "y_log = np.log1p(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e2f8a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor, early_stopping\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "xgb_params = dict(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=1500,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    enable_categorical=False\n",
    ")\n",
    "\n",
    "lgb_params = dict(\n",
    "    objective='mae',\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=15,\n",
    "    min_child_samples=100,\n",
    "    lambda_l1=1.0,\n",
    "    lambda_l2=1.0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d132c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1085\n",
      "[LightGBM] [Info] Number of data points in the train set: 168309, number of used features: 9\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "[LightGBM] [Info] Start training from score 5.610894\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
      "Fold 1 MAE = 18.887\n"
     ]
    }
   ],
   "source": [
    "cv = GroupKFold(n_splits=3)\n",
    "mae_scores = []\n",
    "oof = []\n",
    "\n",
    "for fold, (tr, va) in enumerate(cv.split(X, y_log, groups=df[\"City\"]), 1):\n",
    "    X_tr_xgb, X_va_xgb = X_xgb.iloc[tr], X_xgb.iloc[va]\n",
    "    X_tr_lgb, X_va_lgb = X.iloc[tr], X.iloc[va]\n",
    "    y_tr, y_va = y_log.iloc[tr], y_log.iloc[va]\n",
    "\n",
    "    # --- Train base models ---\n",
    "    xgb = XGBRegressor(**xgb_params)\n",
    "    lgb = LGBMRegressor(**lgb_params)\n",
    "\n",
    "    xgb.fit(X_tr_xgb, y_tr, eval_set=[(X_va_xgb, y_va)], verbose=False)\n",
    "    lgb.fit(X_tr_lgb, y_tr, eval_set=[(X_va_lgb, y_va)],\n",
    "            callbacks=[early_stopping(stopping_rounds=150, verbose=False)])\n",
    "\n",
    "    # --- Predict & inverse-transform ---\n",
    "    pred_xgb = np.expm1(xgb.predict(X_va_xgb))\n",
    "    pred_lgb = np.expm1(lgb.predict(X_va_lgb))\n",
    "\n",
    "    # --- Meta-learner (Ridge stacking) ---\n",
    "    meta = Ridge(alpha=1.0)\n",
    "    meta.fit(np.column_stack([pred_xgb, pred_lgb]), np.expm1(y_va))\n",
    "    stacked = meta.predict(np.column_stack([pred_xgb, pred_lgb]))\n",
    "\n",
    "    # --- Evaluate ---\n",
    "    y_true = np.expm1(y_va)\n",
    "    mae = mean_absolute_error(y_true, stacked)\n",
    "    mae_scores.append(mae)\n",
    "    print(f\"Fold {fold} MAE = {mae:.3f}\")\n",
    "\n",
    "    # --- Store OOF predictions for analysis ---\n",
    "    oof.append(pd.DataFrame({\n",
    "        \"City\": df.loc[va, \"City\"],\n",
    "        \"BuildingType\": df.loc[va, \"BuildingType\"].values,\n",
    "        \"y_true\": y_true,\n",
    "        \"y_pred\": stacked\n",
    "    }))\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Mean Stacked Ensemble MAE: {np.mean(mae_scores):.3f} Â± {np.std(mae_scores):.3f}\")\n",
    "\n",
    "# Combine all folds\n",
    "oof_df = pd.concat(oof, ignore_index=True)\n",
    "oof_df.to_parquet(\"oof_balanced_by_type.parquet\", index=False)\n",
    "print(\"âœ… Saved OOF predictions for error analysis.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f088d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(oof_df.head())\n",
    "print(\"\\nMean absolute error overall:\", mean_absolute_error(oof_df[\"y_true\"], oof_df[\"y_pred\"]))\n",
    "print(\"\\nMAE by BuildingType:\")\n",
    "print(oof_df.groupby(\"BuildingType\").apply(lambda d: mean_absolute_error(d[\"y_true\"], d[\"y_pred\"])))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
